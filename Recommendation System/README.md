# Movie Recommendation System
In today’s world recommender system is being used everywhere eg. spotify, netflix, etc. to recommend songs of a genre similar to the one we were listening to. In Netflix the system recommends movies and shows based on what we have watched earlier. There are 3 types of recommendation system :- <br>
**1. Content Based :-** recommends content based on similarity. If we are listening to POP songs then the recommended songs will also be of the same genre. The recommendation is done using tags. <br>
**2. Collaborative Filtering :-** recommends on the basis of users interest. Suppose A and B are 2 people who have very common taste in movies with a similarity score of 0.9, then if A watches a movie then the same movie will be recommended to B. <br>
**3. Hybrid :-** Includes both the above approaches. Youtube has switched from content based to hybrid.<br>

## Model
Download the dataset from :- https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata
We will make a `content based recommender system`. First we will preprocess the data, then we will build a model, then we will make a website and integrate the model with it. We will use the **`TMDB 5000 dataset`** from kaggle, in this dataset we have features in `movies.csv` and title, cast, crew in `credits.csv`. We will merge both the data frames and then we will drop some features which are not very useful to us. We will merge the data frames on the basis of **title** and then we have a new data frame with 23 columns (features). We will drop the columns on the basis of whether it can help us to create **tags** or not. Eg. The budget of the movie can’t help us as it is not always true that high budget movies are good. The important features are movie_id, title, overview, genres, keywords, cast, crew. Then for tags we will join the overview, genres, keywords, cast (top 3), crew (director) columns. Before this first we will check for missing data by `movies.isnull().sum()`→ 3 missing data are there in the overview column. So we will remove those 3 movies whose overview is missing. Next we will go for duplicate data. `movies.duplicated().sum()`→ 0. Then we will clean the data in our own way.<br>
So the **genre** is in the format of a string of lists, we have to convert it into a list. We can do this using the **`ast library`** as `ast.literal_eval()`. After this we get genres of every movie as a list. We will do the same thing for other columns also. For the cast column we will only take the top 3 names of the cast. For crew we will only consider the `job=director`. The overview column is a string so we have to convert it into a list so that we can join it with others.<br>
While creating tags we should keep in mind that if there is any space between the name of a person that will create 2 tags of the same person. Also if 2 actors have the same name then the model will get confused which to recommend so it is important to remove spaces. After removing the spaces join the 5 columns to get a new **tags column**. Then we have a new data frame with movie_id, title and tags. Then we will convert the tags column into string. And then we will convert the entire string into lower case as it is a good practice. After this we are ready with our dataset. Now our challenge is to find the similarities between the tags of movies. For this we will use **vectorization techniques**, there are many techniques such as **Bag of Words, TFIDF, Word2Vec**. We will use the BOW technique, here we will first join all the tags and then we get a huge string, from this string we will search for **5000 most common words**. Then we will check every tag and count how many times each of the 5000 words had appeared in that tag. Then we will get a matrix of numbers of the shape **5000 X 5000**. <br>
Each row is the vector representation of the tag of that movie. In this process we will remove **stopwords**, words which are used for formation of a sentence but have no contribution in the actual meaning of the sentence. From **`sklearn`** we will import **`CountVectorizer`**. We will also apply **stemming** which will convert all the words to its **base word**. After doing this we will get rid of repetitive words with the same meaning. So in total we have 4806 movies and their corresponding vectors. Now we will calculate the distance between every vector from each other. `More the distance less the similarity`. Note that we will not calculate the **Euclidean distance** we will calculate the **cosine distance**. Euclidean distance calculates the distance between the tip points of the vector and cosine distance is the angle between the vectors, if the angle is 0 then the vectors are similar, if the angle is very small 5-10 then vectors are slightly similar, if the angle is 90 then dissimilar vectors, 180 completely opposite vectors. Euclidean distance is not a good measure, if we are working with huge data it is not advisable to use Euclidean distance. From **`sklearn.metrics.pairwise`** we will use the **`cosine_similarity`** function. We get the similarity matrix, which is a matrix of arrays. In this matrix the first array is the similarity of 1st movie with all 4806 movies.<br>
Now we have to make a function in which we will pass a movie and in return it will recommend 5 similar movies to us. So we will take each array and sort it in ascending order, but here is a problem if we directly apply the sorting then we will lose the indexing, so we have to use the **enumerate function**. **`list(enumerate(similarity[0]))`**→ this will make a list of tuples in which the first element of the tuple is index number. <br>

## Website
We will use a **`streamlit library`** to build the website, to send the output of the ML model into the website we will use the **pickle library**. 
